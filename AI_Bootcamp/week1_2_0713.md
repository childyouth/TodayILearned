# 7월 13일 인공지능부트캠프 TIL  

인공지능 부트캠프 1주_2일차  
Numpy 연산들에 대해 공부했다. Numpy가 일반 python 연산과 속도차이가 꽤 난다는걸 얼게 되었다.  
다른 인공지능 수업들에서 Numpy 연산법에 대해서 보다는 pytorch나 tensorflow 기능들 위주로 공부했다 보니 Numpy slicing 등을 야매?로 했었는데, 지금 공부하니 맞게 사용했던것 같아 다행인 느낌이다.  
  
  
## Numpy  
> Numpy는 계산에 관련해 도움을 주는 라이브러리이다  
  
Numpy 설치
`!pip install numpy`  
  
Numpy는 수학적인 기능의 제공뿐 아니라 연산에도 빠른 모습을 보여준다.  

```
%timeit : jupyter에서 제공하는 연산속도 측정기능

import numpy as np

%timeit [i ** 2 for i in range(1000)]
=> 325ns per loop

%timeit np.arange(1000) ** 2
=> 10.5ns per loop
```
  
Numpy는 python의 기본 container list가 아닌 본인의 array를 사용한다.  

```
arr = np.arry([1,2,3])
arr_2d = np.array([[1,2,3],[4,5,6],[7,8,9]])
```

array의 크기가 궁금할 경우 `shape`속성으로 알 수 있다.
```
arr.shape
=> (3, )

arr_2d.shape
=> (3, 3)
```

---  
  
## Numpy 연산  
  
Vector와 Scalar 사이의 연산은 파이썬의 기본 연산자로서 수행된다.  
  
```
x = np.array([1,2,4])
c = 5

x + c
=> [6 7 9]
x - c
=> [-4 -3 -1]
x * c
=> [5, 10, 20]
x / c
=> [0.2 0.4 0.8]
```
  
  
Vector와 Vector사이의 연산도 파이썬의 기본 연산자로 수행이 되는데, 벡터의 같은 인덱스끼리 연산된다.  
  
```
x = np.array([1,3,5])
y = np.array([2,9,20])

x + y
=> [3 12 25]
x - y
=> [-1 -6 -15]
x * y
=> [2 27 100]
x / y
=> [0.5 0.3333 0.25]
```
  
  
Array의 Indexing은 괄호`[]` 사이에 `,`를 기준으로 나눈다  
  
```
x = np.array([[1,2],[3,4]])

x[0,0]
=> 1
```
  
  
Array Slicing은 파이썬 list와 같이 쓰면 된다.  
  
  
```
x = np.array([[1,2,3],[4,5,6],[7,8,9]])

x[0:2, 1,3] # STARTNUM : ENDNUM 일때 STARTNUM ~ END
=> [[2, 3],
    [5, 6]]
```
  
  

크기가 다른 Array에 대해서 연산가능하게 바꿔주는 기능이 있는데 이를 Broadcasting이라 한다.  
크기를 맞춰 복사가 되게 된다.  
  
```
# M by N, M by 1
a = np.array([[1,2,3],[4,5,6],[7,8,9]])
x = np.array([0,1,0])

x = x[:,None] # 전치 (transpose) 하는 방법 중 하나
a + x
=> [[1 2 3],
    [5 6 7],
    [7 8 9]]

# M by N, 1 by N
y = np.array([0,1,-1])
a * y
=> [[0 2 -3],
    [0 5 -6],
    [0 8 -9]]
```
  
---  

## 선형대수
  
```
np.zeros(dim) : dim차원만큼 0으로 채워진 행렬 생성

np.ones(dim) : dim차원 만큼 1로 채워진 행렬 생성

np.diag( [main_diagonals] ) : 대각선으로 main_diagonals가 채워지고 나머지가 0으로 채워지는 대각행렬

np.eye(n) : main diagonal이 전부 1인 대각 행렬 (:항등행렬)

np.dot( A, B ) or A.dot( B ) or A @ B : 행렬곱 (dot product)

A.trace() : main diagonal들의 합

np.linalg.det( A ) : 행렬을 대표하는 값중 하나인 행렬식 계산

np.linalg.inv( A ) : 행렬 A에 대해 AB = BA = I 를 만족하는 행렬 B 구하기

np.linalg.eig( A ) : 행렬 A에 대해 Ax = (lambda)x 를 만족하는 lambda와 x(고유값, 고유벡터) 구하기
```  
  
  
오랜만에 다시 보는 선형대수가 반갑지는 않다.. 

